{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required packages\n",
    "1. pandas library required for data analysis, in this case to read the dataset file\n",
    "2. linear_model from scikit-learn, for the purpose of using the Logistic Regression algorithm\n",
    ":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as ps\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with reading the training dataset file which contains the input features(Age,SibSp,Parch,Sex,Pclass,Fare,Embarked columns) as well as the output feature(Survived column) required for training the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet=ps.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beginning with data analysis, it is important to do a data cleanup : to deal with empty values and normalize the required data from text to number format so that it is easy for the algorithm to understand the values and optimize them accordingly.\n",
    "\n",
    "1. In the below data_cleanup method, the \"Age\" and \"Fare\" column values which are empty are filled up with the mean of the age column and mode of the fare column respectively(I have used mean and mode just to try different functions, \"median\" can also be used).\n",
    "2. The empty values in the \"Embarked\" column are replaced by default as \"S\".\n",
    "   To make the data algorithm-friendly, I have replaced the values \"S\",\"C\",\"Q\" with 1,2 & 3 respectively.\n",
    "3. The values for the \"Sex\" column are replaced with 1 & 2 for \"female\" & \"male\" respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanup(dataset):\n",
    "    dataset[\"Age\"] = dataset[\"Age\"].fillna(dataset[\"Age\"].dropna().mean())\n",
    "    dataset[\"Fare\"]=dataset[\"Fare\"].fillna(dataset[\"Fare\"].dropna().mean())\n",
    "    dataset[\"Embarked\"]=dataset[\"Embarked\"].fillna(\"S\")\n",
    "    dataset.loc[dataset[\"Embarked\"]==\"S\",\"Embarked\"]=1\n",
    "    dataset.loc[dataset[\"Embarked\"]==\"C\",\"Embarked\"]=2\n",
    "    dataset.loc[dataset[\"Embarked\"]==\"Q\",\"Embarked\"]=3\n",
    "    dataset.loc[dataset[\"Sex\"]==\"female\",\"Sex\"]=1\n",
    "    dataset.loc[dataset[\"Sex\"]==\"male\",\"Sex\"]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data_cleanup method, clean up of the training dataset obtained from the file is performed.\n",
    "\n",
    "Now, the columns required to feed the algorithm are selected from the training dataset and assigned into a variable called featureSet. This will be the input for the algorithm.\n",
    "\n",
    "The output column \"Survived\" is selected and assigned into targetValue variable. This will be referred as the output by the algorithm.\n",
    "\n",
    ":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleanup(trainSet)\n",
    "\n",
    "featureSet=trainSet[[\"Age\",\"SibSp\",\"Parch\",\"Sex\",\"Pclass\",\"Fare\",\"Embarked\"]].values\n",
    "targetValue=trainSet[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, an instance of the LogisticRegression method is created and using the fit method on the instance \"classify\", the input and output features are fed to the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify=linear_model.LogisticRegression()\n",
    "classify_=classify.fit(featureSet,targetValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the classifier can be computed using the score method on the classify_ variable, which in this case is 80%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8002244668911336\n"
     ]
    }
   ],
   "source": [
    "print(classify_.score(featureSet,targetValue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the variation in the accuracy by altering the number of input features as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8035914702581369\n"
     ]
    }
   ],
   "source": [
    "featureSet=trainSet[[\"Age\",\"SibSp\",\"Parch\",\"Sex\",\"Pclass\"]].values\n",
    "targetValue=trainSet[\"Survived\"].values\n",
    "\n",
    "classify=linear_model.LogisticRegression()\n",
    "classify_=classify.fit(featureSet,targetValue)\n",
    "\n",
    "print(classify_.score(featureSet,targetValue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, reading the testing dataset file which contains the input features(Age,SibSp,Parch,Sex,Pclass,Fare,Embarked columns) for testing the algorithm.\n",
    "\n",
    "The data cleanup is done for the test dataset as well using the method defined above.\n",
    "\n",
    "The set of input features is fed into the variable testfeatureSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet=ps.read_csv(\"./data/test_input.csv\")\n",
    "\n",
    "data_cleanup(testSet)\n",
    "\n",
    "testfeatureSet=testSet[[\"Age\",\"SibSp\",\"Parch\",\"Sex\",\"Pclass\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testfeatureSet is passed into the predict method of the classifier instance and the result is recorded in a variable result.\n",
    "The first 20 output results can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first 20 results from the prediction: 0 as deceased and 1 as survived\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=classify_.predict(testfeatureSet)\n",
    "\n",
    "print(\"Printing first 20 results from the prediction: 0 as deceased and 1 as survived\")\n",
    "\n",
    "result[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected output is read from the file test_expected_output which contains the right output to be displayed for the test dataset.\n",
    "\n",
    "The expected output is compared with the classifier to compute the accuracy of the prediction as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "output = ps.read_csv('./data/test_expected_output.csv')\n",
    "targetOutput=output[\"Survived\"].values\n",
    "\n",
    "print(classify_.score(testfeatureSet,targetOutput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
